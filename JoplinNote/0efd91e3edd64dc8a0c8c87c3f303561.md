2.2.1 局部敏感哈希

**近邻快速查找算法**：

* **聚类**：聚类边缘的点的最近邻往往会包括相邻聚类的点，如果我们只在类别内搜索，就会遗漏这些近似点。聚类数目的设置需要考究

* **线性扫描**: 逐一对比
* **KDTree**: 二叉树，核心思想是对K维特征空间不断以中值递归切分构造树，每一个节点是一个超矩形，小于节点的样本划分到左子树，大于节点的样本划分到右子树（维数小于20时效率最高，空间维度接近训练实例数效率迅速下降），无法完全解决边缘点
* **BallTree**：在一系列嵌套的超球面上分割数据，即使用超球面而不是超矩形划分区域。在构建数据结构的花费上大过于KDtree，但是在高维甚至很高维的数据上都表现的很高效
* **Annoy**：同样通过建立一个二叉树来使得每个点查找时间复杂度是O(log n)，和kd树不同的是，annoy没有对k维特征进行切分，Annoy的每一次空间划分，可以看作聚类数为2的KMeans过程
* **NSW(Navigable small world graphs)**: 基于图存储的数据结构，当我想查找与粉色点最近的一点时，我从任意一个黑色点出发，计算它和粉色点的距离，与这个任意黑色点有连接关系的点我们称之为“友点”（直译），然后我要计算这个黑色点的所有“友点”与粉色点的距离，从所有“友点”中选出与粉色点最近的一个点，把这个点作为下一个进入点，继续按照上面的步骤查找下去。如果当前黑色点对粉色点的距离比所有“友点”都近，终止查找，这个黑色点就是我们要找的离粉色点最近的点  
  ​![img](https://pic3.zhimg.com/80/v2-9d6e14f291018de4c4ae6a25e38497e2_1440w.jpg)  
  **缺陷：**

  * **孤点无法被找到->所有数据向量节点都必须有友点**
  * **近点必须有连线->所有距离相近（相似）到一定程度的向量必须互为友点**
  * **友点数目要控制->尽量减少每个节点的“友点”数量**
* **HNSW：加入了跳表结构做了进一步优化。最底层是所有数据点，每一个点都有50%概率进入上一层的有序链表。这样可以保证表层是“高速通道”，底层是精细查找。**

![image.png](:/bf84902423cb4397ad76b2b734be892e)

**局部敏感哈希实践**：利用 Sparrow Recsys 训练好的物品 Embedding，来实现局部敏感哈希的快速搜索吧。为了保证跟 Embedding 部分的平台统一，这一次我们继续使用 Spark MLlib 完成 LSH 的实现。在将电影 Embedding 数据转换成 dense Vector 的形式之后，我们使用 Spark MLlib 自带的 LSH 分桶模型 BucketedRandomProjectionLSH（我们简称 LSH 模型）来进行 LSH 分桶。其中最关键的部分是设定 LSH 模型中的 BucketLength 和 NumHashTables 这两个参数。其中，BucketLength 指的就是分桶公式中的分桶宽度 w，NumHashTables 指的是多桶策略中的分桶次数。清楚了模型中的关键参数，执行的过程就跟我们讲过的其他 Spark MLlib 模型一样了，都是先调用 fit 函数训练模型，再调用 transform 函数完成分桶的过程，具体的实现你可以参考下面的代码。

```scala

def embeddingLSH(spark:SparkSession, movieEmbMap:Map[String, Array[Float]]): Unit ={
  //将电影embedding数据转换成dense Vector的形式，便于之后处理
  val movieEmbSeq = movieEmbMap.toSeq.map(item => (item._1, Vectors.dense(item._2.map(f => f.toDouble))))
  val movieEmbDF = spark.createDataFrame(movieEmbSeq).toDF("movieId", "emb")


  //利用Spark MLlib创建LSH分桶模型
  val bucketProjectionLSH = new BucketedRandomProjectionLSH()
    .setBucketLength(0.1)
    .setNumHashTables(3)
    .setInputCol("emb")
    .setOutputCol("bucketId")
  //训练LSH分桶模型
  val bucketModel = bucketProjectionLSH.fit(movieEmbDF)
  //进行分桶
  val embBucketResult = bucketModel.transform(movieEmbDF)
  
  //打印分桶结果
  println("movieId, emb, bucketId schema:")
  embBucketResult.printSchema()
  println("movieId, emb, bucketId data result:")
  embBucketResult.show(10, truncate = false)
  
  //尝试对一个示例Embedding查找最近邻
  println("Approximately searching for 5 nearest neighbors of the sample embedding:")
  val sampleEmb = Vectors.dense(0.795,0.583,1.120,0.850,0.174,-0.839,-0.0633,0.249,0.673,-0.237)
  bucketModel.approxNearestNeighbors(movieEmbDF, sampleEmb, 5).show(truncate = false)
}
```

事实上，在一些超大规模的最近邻搜索问题中，索引、分桶的策略还能进一步复杂。如果有兴趣深入学习可以参考： https://github.com/facebookresearch/faiss


id: 0efd91e3edd64dc8a0c8c87c3f303561
parent_id: f91d99bae8504618b2112052e8e244dc
created_time: 2023-03-25T10:09:46.803Z
updated_time: 2023-03-31T12:47:38.748Z
is_conflict: 0
latitude: 0.00000000
longitude: 0.00000000
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 1680266858711
user_created_time: 2023-03-25T10:09:46.803Z
user_updated_time: 2023-03-31T12:47:38.748Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
type_: 1