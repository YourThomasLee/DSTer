Bayesian methods

## 0.1 PRML(Chapters 1介绍,2概率分布,3 回归的线性模型, 9 混合模型和EM,10 近似推断)

### Chapters 1 Introduction

寻找数据中的模式的问题是一个基本问题, 例如16世纪Tycho Brahe的⼤量的观测使得Johannes Kepler发现⾏星运⾏的经验性规律，这反过来给经典⼒学的发展提供了跳板.

> 运⾏机器学习算法的结果可以被表⽰为⼀个函数$y(x)$，它以⼀个新的数字的图像$x$为输⼊，产⽣向量$y$，与⽬标向量的形式相同。函数$y(x)$的精确形式在训练（training）阶段被确定，这个阶段也被称为学习（learning）阶段，以训练数据为基础。⼀旦模型被训练出来，它就能确定新的数字的图像集合中图像的标签。这些新的数字的图像集合组成了测试集（test set）。正确分类与训练集不同的新样本的能⼒叫做泛化（generalization）
>
> 训练数据的样本包含输⼊向量以及对应的⽬标向量的应⽤叫做有监督学习（supervised  
> learning）问题. 数字识别就是这个问题的⼀个例⼦，它的⽬标是给每个输⼊向量分配到有限数量离散标签中的⼀个，被称为分类（classification）问题。如果要求的输出由⼀个或者多个连续变量组成，那么这个任务被称为回归（regression）.
>
> 训练数据由⼀组输⼊向量x组成，没有任何对应的⽬标值。在这样的⽆监督学习（unsupervised learning）问题中，⽬标可能是发现数据中相似样本的  
> 分组，这被称为聚类（clustering），或者决定输⼊空间中数据的分布，这被称为密度估计（density estimation）
>
> 强化学习（reinforcement learning）（Sutton and Barto, 1998）技术关注的问题是在给定的条件下，找到合适的动作，使得奖励达到最⼤值
>

#### C1.1 例子: 多项式拟合

数据本身存在内在的规律, 但数据是包含噪声观测的结果. 我们建立机器学习算法的目标是获取具有泛化性的算法(真实的内在规律), 但不确定性(噪声/建模)导致学习到真正的内在规律是困难的.

不确定性的来源:

* 数据观测, 观测包含的噪声太大, 导致真实的规律已经被隐藏; 观测场景的复杂和观测数据的量大小
* 建模:

  * 特征构建: 如果特征建模对噪声过于敏感, 那么学习器学习内在规律将是一个具有挑战性的任务
  * 模型选择: 各种规律对应不同的模型学习成本存在差异, 因此必须根据具体场景来选择不同的模型
  * 学习目标: 学习目标建立在模型和数据的基础上, 因此学习目标/损失函数的设计非常重要


#### C1.2 概率论

在模式识别领域的⼀个关键概念是不确定性的概念。它可以由测量的误差引起，也可以由数据集的有限⼤⼩引起。概率论提供了⼀个合理的框架，⽤来对不确定性进⾏量化和计算。概率论还构成了模式识别的⼀个中⼼基础。当与决策论（1.5节讨论）结合，概率论让我们能够根据所有能得到的信息做出最优的预测，即使信息可能是不完全的或者是含糊的。

概率加和规则: $p(X)=\sum_{Y} p(X, Y)$  

概率乘积规则: $p(X, Y)=p(Y|X)p(X)$  

贝叶斯定理: $p(Y|X)=\frac{p(X|Y)p(Y)}{p(X)}$, 我们可以把贝叶斯定理的分母看作归一化常数, 用来确保分子之和为1

概率的动静之分: 我们根据随机重复事件的频率来考察概率。我们把这个叫做经典的（classical）或者频率学家（frequentist）的关于概率的观点(静态, 真理是永恒不变的)。贝叶斯定理通过将观察到的数据融合，来把先验概率转化为后验概率. 后验概率等价于似然函数和先验概率的积(动态, 真理是不变的, 但运动是永恒的, 问题在不断变化).

我们对于参数$w$的假设, 这以$p(w)$的形式给出. 观测数据$D=\{t_1, \cdots, t_N\}$的效果可以通过条件$p(D|w)$表达, 贝叶斯定理的形式为$p(w|D)=\frac{p(D|w)p(w)}{p(D)}$, 它能让我们能够通过后验概率$p(w|D)$, 在通过$D$后估计$w$的不确定性.

频率学家广泛使用的一个估计是最大似然估计, 其中$w$的值是使似然函数$p(D|w)$达到最大值的$w$值. 在机器学习的文献中, 似然函数的负对数被叫做误差函数(error function).

**从贝叶斯角度考察曲线拟合**(将预测值变为一个分布, 并对参数增加超参先验): 曲线拟合问题的⽬标是能够根据$N$个输⼊$X = (x_1,\cdots,x_N)^T$ 组成的数据集和它们对应的⽬标值$T=(t_1,\cdots,t_N)^T$. 在给定输入变量$x$的情况下, 对目标变量$t$进行预测. 我们可以使用概率分布来表达关于目标变量的值的不确定性.

为了达到这个目的, 我们要假定, 给定$x$的值, 对应的$t$值服从高斯分布, 其均值为$y(x, \omega)$, 因此我们有$p(t|x,\omega,\beta) = N(t|y(x, \omega), \beta ^ {-1})$. 然后可以使用最大似然估计$p(t|x,\omega,\beta) =\prod_{n=1}^N N(t_n|y(x_n, \omega), \beta ^ {-1})$, 可以得到似然函数 $\ln p(t|x,\omega,\beta) =-\frac{beta}{2} \sum_{n=1}^{N} \{y(x, \omega) - t\}^2+\frac{N}{2}\ln \beta - \frac{N}{2}\ln(2\pi)$.  

基于似然估计可以先得到对应多项式系数的最大似然解$\omega_{ML}$. 之后可以使用最大似然方法来确定高斯条件分布的精度参数$\beta$, 有$\frac{1}{\beta_{ML}}=\frac{1}{N}\sum_{n=1}^{N} \{y(x_n,\omega_{ML})-t_n\}^2$. 我们又一次首先确定控制均值的参数向量$w_{ML}$, 然后使用这个结果来确定$\beta_{ML}$, 这与简单高斯分布时情形相同.

在已经确定了参数$w,\beta$后, 我们现在可以对新的$x$的标签值进行预测. 由于我们现在有一个概率模型, 预测可以通过给出$t$的概率分布的预测分布来表示(一个分布的估计, 而非一个点估计). 预测分布通过把最大似然参数代入$p(t|x,\omega_{ML},\beta_{ML}) = N(t|y(x, \omega_{ML}), \beta_{ML} ^ {-1})$. 现在让我们朝着贝叶斯的方法前进一步, 引入在多项式系数$w$的先验分布. 简单起见, 可以考虑$p(w|\alpha)=N(w|0, \alpha^{-1}I)=(\frac{\alpha}{2\pi})^{\frac{M+1}{2}}\exp \\{ \frac{-\alpha}{2}w^Tw}$. 其中$\alpha$是分布的精度, $M+1$是对于$M$阶多项式的向量$w$的元素的总数. 对于超参数$\alpha$的值可以使用最大化后验概率来获取. $p(w|X,T,\alpha, \beta) \sim p(T|X,w,\beta)p(w|\alpha)$, 最大化后验概率就是$\frac{\beta}{2}\sum_{n=1}^{N}\{y(x_n,w)-t_n\}2^+\frac{\alpha}{2}w^tw$, 我们可以看到最大化后验概率等价于最小化正则化的平方和误差函数.


**贝叶斯曲线拟合**(将预测分布的表示变为一个求和公式): 在⼀个纯粹的贝叶斯⽅法中，我们应该⾃始⾄终地应⽤概率的加和规则和乘积规则. 在曲线拟合问题中, 我们知道训练数据$X,T$, 以及一个新的测试点$x$, 我们的目标是预测$t$的值. 因此我们想预测分布$p(t|x,X,T)$. 这⾥我们要假设参数$\alpha$和$\beta$是固定的，事先知道的(后续章节讨论如何使用贝叶斯方法从数据中推断出来). **简单的说, 贝叶斯⽅法就是⾃始⾄终地使⽤概率的加和规则和乘积规则。**因此概率预测可以写成下面的形式$p(t|x,X,T)=\int p(t|x,w)p(w|x,t)dw$.


#### C1.3 模型选择

在最⼤似然⽅法中，由于过拟合现象，模型在训练集上的表现并不能很好地表⽰模型对于未知数据的预测能⼒。如果数据量很⼤，那么模型选择很简单。使⽤⼀部分可得到的数据，可以训练出⼀系列的模型，也可以得到某个给定模型的⼀系列复杂度的参数值。之后在独⽴数据上（有时被称为验证集）⽐较它们，选择预测表现最好的模型即可。如果模型的设计使⽤有限规模的数据集迭代很多次，那么对于验证数据会发⽣⼀定程度的过拟合，因此保留⼀个第三⽅的测试集是很有必要的。这个测试集⽤来最终评估选择的模型的表现。

但是在许多实际应⽤中，训练数据和测试数据都是很有限的。为了建⽴好的模型，我们想使⽤尽可能多的可得到的数据进⾏训练。然⽽，如果验证集很⼩，它对预测表现的估计就会有⼀定的噪声。解决这种困境的⼀种⽅法是使⽤交叉验证（cross validation），这种⽅法能够让可得到数据的$\frac{S-1}{S}$⽤于训练，同时使⽤所有的数据来评估表现。在最坏的情况下，探索这些参数的组合所需的训练次数可能是参数个数的指数函数。很显然，我们需要⼀种更好的⽅法. 理想情况下，模型的选择应该只依赖于训练数据，并且应该允许在⼀轮训练中对⽐多个超参数以及模型类型。因此我们需要找到⼀种模型表现的度量，它只依赖于训练数据，并且不会由于过拟合产⽣偏移的问题。

历史上各种各样的“信息准则”被提出来。这些“信息准则”尝试修正最⼤似然的偏差。修正的⽅法是增加⼀个惩罚项来补偿过于复杂的模型造成的过拟合。⾚池信息准则（Akaike information criterion），或者简称为AIC（Akaike, 1974），选择下⾯使这个量最⼤的模型：$\ln p(D|w_{ML}) - M$. $p(D|w_{ML})$是合适的似然函数, $M$为可调节参数的数量. 这个量的⼀种变体，被称为贝叶斯信息准则（Bayesian information criterion），或者简称为BIC. 这种准则没有考虑模型参数的不确定性，在实际应⽤中它们倾向于选择过于简单的模型。

#### C1.4 维度灾难

对于模式识别的实际应⽤来说，我们不得不处理由许多输⼊变量组成的⾼维空间. ⼀种简单的⽅式是把输⼊空间划分成⼩的单元格，当给出测试点，我们要预测类别的时候，我们⾸先判断它属于哪个单元格，然后我们寻找训练集中落在同⼀个单元格中的训练数据点。测试点的类别就是测试点所在的单元格中数量最多的训练数据点的类别。

⾼维空间产⽣的这种困难有时被称为维度灾难（curse of dimensionality） （Bellman, 1961）虽然维度灾难在模式识别应⽤中是⼀个重要的问题，但是它并不能阻⽌我们寻找应⽤于⾼维空间的有效技术。原因有两⽅⾯。第⼀，真实的数据经常被限制在有着较低的有效维度的空间区域中，特别地，在⽬标值会发⽣重要变化的⽅向上也会有这种限制。第⼆，真实数据通常⽐较光滑（⾄少局部上⽐较光滑），因此⼤多数情况下，对于输⼊变量的微⼩改变，⽬标值的改变也很⼩，因此对于新的输⼊变量，我们可以通过局部的类似于插值的技术来进⾏预测。成功的模式识别技术利⽤上述的两个性质中的⼀个，或者都⽤.


#### C1.5 决策论

在1.2节中，我们已经看到了概率论是如何提供给我们⼀个⾃始⾄终的数学框架来量化和计算不确定性。这⾥我们将要转⽽讨论决策论。当决策论与概率论结合的时候，我们能够在涉及到不确定性的情况下做出最优的决策。这在模式识别中经常遇到。

假设我们有⼀个输⼊向量$x$和对应的⽬标值向量$t$，我们的⽬标是对于⼀个新的$x$值，预测$t$。对于回归问题，$t$由连续变量组成，⽽对于分类问题，$t$表⽰类别标签。联合概率分布$p(x; t)$完整地总结了与这些变量相关的不确定性。

从训练数据集中确定$p(x; t)$是推断（inference）问题的⼀个例⼦，并且通常是⼀个⾮常难的问题。在⼀个实际应⽤中，我们经常必须对t的值做出具体的预测，或者更⼀般地，根据我们对于$t$的可能取值的理解，采取⼀个具体的动作。这⼀⽅⾯就是决策论的主题。

在给出⼀个更详细的分析之前，让我们⾸先⾮形式化地考虑⼀下概率论如何在做决策时起作⽤。当我们得到⼀个新病⼈的$X$光⽚$x$时，我们的⽬标是判断这个$X$光⽚属于两类中的哪⼀类. 我们感兴趣的是在给定给定这个图像的前提下，两个类的概率，使用贝叶斯定理也即

$p(C_k | x)=\frac{p(x|C_k) p(C_k)}{p(x)}$  

注意, 出现在贝叶斯定理中的任意一个量都可以从联合分布$p(x, C_k)$中得到，要么通过积分的⽅式，要么通过关于某个合适的变量求条件概率. 我们现在把$p(C_k)$称为类$C_k$的先验概率，把$p(C_k|x)$称为对应的后验概率。因此$p(C1)$表⽰在我们拍$X$光之前，⼀个⼈患癌症的概率。类似地，$p(C_1 |x)$表⽰使⽤X光中包含的信息通过贝叶斯定理修改之后的对应的后验概率。如果我们的⽬标是最⼩化把$x$分到错误类别中的可能性，那么根据直觉，我们要选择有最⼤后验概率的类别。我们现在要证明，这种直觉是正确的，并且我们还会讨论进⾏决策的更加通⽤的标准。

**最小化错误分类率**: 假定我们的⽬标很简单，即尽可能少地作出错误分类。我们需要⼀个规则来把每个$x$的值分到⼀个合适的类别。这种规则将会把输⼊空间切分成不同的区域Rk，这种区域被称为决策区域（decision region）。每个类别都有⼀个决策区域，区域Rk中的所有点都被分到Ck类。决策区域间的边界被叫做决策边界（decision boundary）或者决策⾯（decision surface）. 注意，每⼀个决策区域未必是连续的，可以由若⼲个分离的区域组成。为了找到最优的决策规则，⾸先考虑两类的情形，就像癌症问题的例⼦中那样。如果我们把属于$C_1$类的输⼊向量分到了$C_2$类（或者相反），那么我们就犯了⼀个错误。这种事情发⽣的概率为

$$
p(\text{mistake})=p(x\in R_1, C_2) + p(x \in R_2, C_1) \\=\int_{R_1} p(x, C_2)dx + \int_{R_2} p(x, C_1)dx
$$

很明显, ，为了最⼩化$p(\text{mistake})$，我们对于$x$的分类结果应该让以上公式的被积函数尽量⼩. 因此如果对于给定的$x$值, 如果$p(x, C_1)>p(x,C_2)$, 那么我们就把$x$分到类别$C_1$中. 根据概率的乘积规则, 我们有$p(x,C_k)=p(C_k|x)p(x)$. 由于因子$p(x)$对于两项都相同, 因此我们可以这样表述: 如果我们把每个$x$分配到后验概率$p(C_k | x)$最⼤的类别中，那么我们分类错误的概率就会最⼩。对于更一般的$K$类情形, 最大化正确率会稍微更简单一些, 即最大化下式

$$
p(\text{correct})=\sum_{k=1}^Kp(x\in R_k, C_k) = \sum_{k=1}^K \int_{R_k} p(x, C_k)dx
$$

**最小化期望损失**: 对于许多应⽤，我们的⽬标要⽐单纯地最⼩化错误分类的数量更加复杂。让我们再次考虑医疗诊断的问题。我们注意到，如果已给没有患癌症的病⼈被错误地诊断为患病，结果可能给病⼈带来⼀些压⼒，并且病⼈可能需要进⼀步确诊。相反，如果患癌症的病⼈被诊断为健康，结果可能会因为缺少治疗⽽使病⼈过早死亡。因此这两种错误的结果是相当不同的。很明显，对于第⼆种错误，我们最好少犯，甚⾄由于少犯第⼆种错误会导致第⼀种错误增加也没关系。

我们可以通过损失函数（loss function）来形式化地描述这个问题。损失函数也被称为代价函数（cost function），是对于所有可能的决策或者动作可能产⽣的损失的⼀种整体的度量。我们的⽬标是最⼩化整体的损失。注意，有些学者不考虑损失函数，⽽是考虑效⽤函数（utility function），并且要最⼤化这个函数。如果我们让效⽤函数等于损失函数的相反数的话，那么这些概念是等价的，因此整本书中我们都将使⽤损失函数这个概念。

假设对于新的$x$的值，真实的类别为$C_k$，我们把$x$分类为$C_j$（其中$j$可能与$k$相等，也可能不相等）。这样做的结果是，我们会造成某种程度的损失，记作$L_{kj}$，它可以看成损失矩阵（loss matrix）的第$k, j$个元素。最优解是使损失函数最⼩的解。但是，损失函数依赖于真实的类别，这是未知的。对于⼀个给定的输⼊向量x，我们对于真实类别的不确定性通过联合概率分布p(x; Ck)表⽰。因此，我们转⽽去最⼩化平均损失。平均损失根据这个联合概率分布计算，定义为

$$
E(L)=\sum_k\sum_j\int_{R_j} L_{kj}p(x, C_k)dx
$$

因此，最⼩化期望损失的决策规则是对于每个新的$x$，把它分到能使下式取得最⼩值的第$j$类：

$$
\sum_k L_{kj} p(C_k|x)
$$

⼀旦我们知道了类的后验概率$p(C_k | x)$之后，这件事就很容易做了

**拒绝选项**: 我们已经看到，在发⽣分类错误的输⼊空间中，后验概率p(Ck j x)通常远⼩于1，或者等价地，不同类别的联合分布p(x; Ck)有着可⽐的值。这些区域中，类别的归属相对不确定。在某些应⽤中，对于这种困难的情况，避免做出决策是更合适的选择。这样会使得模型的分类错误率降低。这被称为拒绝选项（reject option）。我们可以⽤这种⽅式来达到这个⽬的：引⼊⼀个阈值$\theta$，拒绝后验概率$p(C_k | x)$的最⼤值⼩于等于$\theta$的那些输⼊$x$(在我们假想的医疗例⼦中，使⽤⾃动化的系统来对那些⼏乎没有疑问的X光⽚进⾏分类，然后把不容易分类的X光⽚留给⼈类的专家).

**推断和决策**: 我们已经把分类问题划分成了两个阶段：推断（inference）阶段和决策（decision）阶段。在  
推断阶段，我们使⽤训练数据学习$p(C_k | x)$的模型。在接下来的决策阶段，我们使⽤这些后验概率来进⾏最优的分类。另⼀种可能的⽅法是，同时解决两个问题，即简单地学习⼀个函数，将输⼊$x$直接映射为决策。这样的函数被称为判别函数（discriminant function）。

事实上，我们可以区分出三种不同的⽅法来解决决策问题，这三种⽅法都已经在实际应⽤问题中被使⽤。这三种⽅法按照复杂度降低的顺序给出：

1. 生成式模型: 显式地或者隐式地对输⼊以及输出进⾏建模的⽅法被称为⽣成式模型（generative model），因为通过取样，可以⽤来⼈⼯⽣成出输⼊空间的数据点。⾸先对于每个类别$C_k$，独⽴地确定类条件密度$p(x | C_k)$。这是⼀个推断问题。然后，推断先验类概率$p(C_k)$。之后，使⽤贝叶斯定理$p(C_k|x)=\frac{p(x|C_k)p(C_k)}{p(x)}$. 求出后验类概率$p(C_k|x)$. 和往常一样, 贝叶斯定理的分母可以用分子中出现的项表示, 因为$p(x)=\sum_k p(x|C_k)p(C_k)$, 等价地, ，我们可以直接对联合概率分布$p(x, C_k)$建模，然后归⼀化，得到后验概率。得到后验概率之后，我们可以使⽤决策论来确定每个新的输⼊$x$的类别。
2. 判别式模型: 直接对后验概率建模的⽅法被称为判别式模型（discriminative models）。解决确定后验类密度$p(C_k | x)$这⼀推断问题，接下来使⽤决策论来对新的输⼊$x$进⾏分类。
3. 找到⼀个函数$f(x)$，被称为判别函数。这个函数把每个输⼊$x$直接映射为类别标签。例如，在⼆分类问题中，$f(x)$可能是⼀个⼆元的数值，$f = 0$表⽰类别$C_1$，$f = 1$表⽰类别$C_2$。

⽅法(1)需要求解的东西最多，因为它涉及到寻找在$x$和$C_k$上的联合概率分布。对于许多应⽤，$x$的维度很⾼，这会导致我们需要⼤量的训练数据才能在合理的精度下确定类条件概率密度。注意，先验概率$p(C_k)$经常能够根据训练数据集⾥的每个类别的数据点所占的⽐例简单地估计出来。但是，⽅法(a)的⼀个优点是，它能够通过公式$p(x)=\sum_k p(x|C_k)p(C_k)$求出数据的边缘概率密度$p(x)$。这对于检测模型中具有低概率的新数据点很有⽤，这些点，模型的预测准确率可能会很低。这种技术被称为离群点检测（outlier detection）或者异常检测（novelty detection）.

如果我们只想进⾏分类的决策，那么这种⽅法会浪费计算资源。并且，实际上我们只是想求出后验概率$p(C_k | x)$（可以直接通过⽅法(2)求出），但是为了求出它，这种⽅法需要⼤量的数据来寻找联合概率$p(x, C_k)$。

更简单的⽅法是⽅法(3)。这种⽅法中，我们使⽤训练数据来寻找将每个$x$直接映射为类别标签的判别函数$f(x)$。使⽤⽅法(3)，我们不在能够接触到后验概率$p(C_k | x)$. 有很多强烈的理由需要计算后验概率，即使我们接下来要使⽤后验概率来进⾏决策。这些理由包括

* 最小化风险: 考虑这样⼀个问题，问题中损失矩阵的元素时时刻刻都被修改(例如⾦融应⽤中可能出现的情况).  如果我们知道后验概率，我们只需要恰当地修改公式所定义的最⼩风险决策准则即可
* 拒绝选项。如果给定被拒绝的数据点所占的⽐例，后验概率让我们能够确定最⼩化误分类  
  率的拒绝标准，或者在更⼀般的情况下确定最⼩化期望损失的拒绝标准。
* 补偿类先验概率: 对于类别不平衡问题, 可以考虑制造⼀个平衡的数据集⾥，我们已经从每个类别中选择了相等数量的样本，这让我们能够找到⼀个更加准确的模型。然⽽，我们之后就必须补偿修改训练数据所造成的影响。假设我们已经使⽤这种修改后的数据，找到了后验概率的模型。根据$p(C_k|x)=\frac{p(x|C_k)p(C_k)}{p(x)}$的贝叶斯定理, 我们看到后验概率正⽐于先验概率，⽽先验概率可以表⽰为每个类别的数据点所占的⽐例。因此我们可以把从⼈造的平衡数据中得到的后验概率除以数据集⾥的类⽐例，再乘以我们想要应⽤模型的⽬标⼈群中类别的⽐例即可。最后，我们需要归⼀化来保证新的后验概率之和等于1(如果我们直接学习一个判别函数而不确定后验概率, 这个步骤就无法进行)。

* 组合模型: 对于复杂的应⽤来说，我们可能希望把问题分解成若⼲个⼩的⼦问题，每个⼦问题都可以通过⼀个独⽴的模型解决。例如，在我们假想的医疗诊断问题中，我们可能有来⾃⾎液检查的数据，以及X光⽚。我们不把所有的这种同样类型的信息集中到⼀个巨⼤的输⼊空间中，⽽是建⽴⼀个系统来表⽰X光⽚⽽另⼀个系统来表⽰⾎液数据。这样做效率更⾼。只要两个模型都给出类别的后验概率，我们就能够使⽤概率的规则系统化地结合输出。。只要两个模型都给出类别的后验概率，我们就能够使⽤概率的规则系统化地结合输出。完成这个⽬标的⼀个简单的⽅式是假设对于每个类别，X光⽚的输⼊的分布（记作$x_I$）和⾎液数据的输⼊的分布（记作$x_B$）是独⽴的，因此$p(x_I, x_B, | C_k) = p(x_I|C_k) p(x_B|C_k)$, 同时给出$X$光片和血液数据, 后验概率为$p(C_k|x_I, x_B) \propto p(x_I, x_B|C_k)p(C_k) \propto p(x_I|C_k)p(x_B|C_k)p(C_k)\propto \frac{p(C_k|x_I)p(C_k|x_B)}{p(C_k)}$. 因此我们可以先求出先验概率$p(C_k)$, 之后对后验概率归一化.

**回归问题的损失函数**: 决策阶段包括对于每个输⼊$x$，选择⼀个对于$t$值的具体的估计$y(x)$。假设这样做之后，我们造成了⼀个损失$L(t, y(x))$。平均损失（或者说期望损失）就是$E[L]=\int\int L(t,y(x)) p(x,t) dx dt$. 回归问题中损失函数的一个常规选择是平方损失, 定义为$L(t, y(x))=\{y(x)-t\}^2$, 这种情况下, 期望损失函数可以写成$E[L]=\int\int \{y(x)-t\}^2p(x,t) dx dt$. 我们的目标是选择$y(x)$来最小化$E[L]$. 如果我们假设一个完全任意的函数$y(x)$, 我们能够形式化地使用变分法求解: 

$$
\frac{\delta E[L]}{\delta y(x)}=2\int \{y(x)-t\}p(x,t)dt=0
$$

求解$y(x)$使用概率加和规则和乘积规则我们得到

$$
y(x)=\frac{\int tp(x,t)dt}{p(x)}=\int tp(t|x)dt = E[t|x]
$$

这是在条件$x$下的条件均值, 被称为回归函数(regression funciton). 这个结果可以扩展到多个⽬标变量（⽤向量$t$）的情形。这种情况下，最优解是条件均值$y(x) = E_t[t | x]$.


#### C1.6 信息论

介绍了熵的概念, 历史, 函数极值等特性.

熵$H[p]=-\sum_i p(x_i)\ln p(x_i)$  

条件熵: $H[y|x]=-\int \int p(y,x) ln p(y|x) dy dx$  

相关关系: $H[x, y]=H[y|x] + H[x]$  

相对熵(KL散度): $KL(p||q)=-\int p(x) \ln q(x) dx - (-\int p(x) \ln p(x) dx ) = -\int p(x) \ln \frac{q(x)}{p(x)}dx$  

互信息: $I[x,y]=KL(p(x,y)||p(x)p(y))-\int\int p(x,y) \ln \frac{p(x)p(y)}{p(x,y)}dx dy=H[x]-H[x|y]=H[y]-H[y|x]$  


## C2 概率分布 -- 主要是一些概率基础知识

参数⽅法的⼀个限制是它假定分布有⼀个具体的函数形式，这对于⼀个具体应⽤来说是不合适的。另⼀种替代的⽅法是⾮参数（nonparametric）密度估计⽅法。这种⽅法中分布的形式通常依赖于数据集的规模。这些模型仍然具有参数，但是这些参数控制的是模型的复杂度⽽不是分布的形式. 本章最后，我们会考虑三种⾮参数化⽅法，分布依赖于直⽅图、最近邻以及核函数。

**顺序估计**: 顺序的⽅法允许每次处理⼀个数据点，然后丢弃这个点。这对于在线应⽤很重要。并且当数据集相当⼤以⾄于⼀次处理所有数据点不可⾏的情况下，顺序⽅法也很重要(Robbins-Monro算法)。

# 0.2 Bayesian methods in machine learning


id: a987cd17098a4fe484c0be3a422eab5f
parent_id: 1d6c738b3efe43cdb4e853ef51ce1f61
created_time: 2023-03-26T03:26:51.962Z
updated_time: 2023-03-31T12:46:41.764Z
is_conflict: 0
latitude: 0.00000000
longitude: 0.00000000
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 1680266801735
user_created_time: 2023-03-26T03:26:51.962Z
user_updated_time: 2023-03-31T12:46:41.764Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
type_: 1