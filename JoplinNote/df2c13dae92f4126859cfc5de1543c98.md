2.2 召回技术

召回层就是要快速、准确地过滤出相关物品，缩小候选集，排序层则要以提升推荐效果为目标，作出精准的推荐列表排序。再详细一点说，我们可以从候选集规模、模型复杂程度、特征数量、处理速度、排序精度等几个角度来对比召回层和排序层的特点：![image.png](:/b963bab2dc5d4f3491ec2dcb6572a982)

单策略召回指的是，通过制定一条规则或者利用一个简单模型来快速地召回可能的相关物品, 拿 SparrowRecSys 里面的电影推荐为例。在推荐电影的时候，我们首先要想到用户可能会喜欢什么电影。按照经验来说，很有可能是这三类，分别是大众口碑好的、近期非常火热的，以及跟我之前喜欢的电影风格类似的。基于其中任何一条，我们都可以快速实现一个单策略召回层。比如在 SparrowRecSys 中，我就制定了这样一条召回策略：如果用户对电影 A 的评分较高，比如超过 4 分，那么我们就将与 A 风格相同，并且平均评分在前 50 的电影召回，放入排序候选集中。

```java
//详见SimilarMovieFlow class
public static List<Movie> candidateGenerator(Movie movie){
    ArrayList<Movie> candidates = new ArrayList<>();
    //使用HashMap去重
    HashMap<Integer, Movie> candidateMap = new HashMap<>();
    //电影movie包含多个风格标签
    for (String genre : movie.getGenres()){
        //召回策略的实现
        List<Movie> oneCandidates = DataManager.getInstance().getMoviesByGenre(genre, 100, "rating"); 
        for (Movie candidate : oneCandidates){
            candidateMap.put(candidate.getMovieId(), candidate);
        }
    }
    //去掉movie本身
    if (candidateMap.containsKey(movie.getMovieId())){
        candidateMap.remove(movie.getMovieId());
    }
    //最终的候选集
    return new ArrayList<>(candidateMap.values());
}
```

单策略的特点是计算速度非常快，有很强的局限性，不能衡量多元的兴趣

所谓“**多路召回策略**”，就是指采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合在一起供后续排序模型使用的策略。

下面是我给出的电影推荐中常用的多路召回策略，包括热门电影、风格类型、高分评价、最新上映以及朋友喜欢等等。除此之外，我们也可以把一些推断速度比较快的简单模型（比如逻辑回归，协同过滤等）生成的推荐结果放入多路召回层中，形成综合性更好的候选集。具体的操作过程就是，我们分别执行这些策略，让每个策略选取 Top K 个物品，最后混合多个 Top K 物品，就形成了最终的多路召回候选集。整个过程就如下所示：![image.png](:/365a870973624b36af8194129b129941)

在 SparrowRecsys 中，我们就实现了由风格类型、高分评价、最新上映，这三路召回策略组成的多路召回方法，具体代码如下：

```java

public static List<Movie> multipleRetrievalCandidates(List<Movie> userHistory){
    HashSet<String> genres = new HashSet<>();
    //根据用户看过的电影，统计用户喜欢的电影风格
    for (Movie movie : userHistory){
        genres.addAll(movie.getGenres());
    }
    //根据用户喜欢的风格召回电影候选集
    HashMap<Integer, Movie> candidateMap = new HashMap<>();
    for (String genre : genres){
        List<Movie> oneCandidates = DataManager.getInstance().getMoviesByGenre(genre, 20, "rating");
        for (Movie candidate : oneCandidates){
            candidateMap.put(candidate.getMovieId(), candidate);
        }
    }
    //召回所有电影中排名最高的100部电影
    List<Movie> highRatingCandidates = DataManager.getInstance().getMovies(100, "rating");
    for (Movie candidate : highRatingCandidates){
        candidateMap.put(candidate.getMovieId(), candidate);
    }
    //召回最新上映的100部电影
    List<Movie> latestCandidates = DataManager.getInstance().getMovies(100, "releaseYear");
    for (Movie candidate : latestCandidates){
        candidateMap.put(candidate.getMovieId(), candidate);
    }
    //去除用户已经观看过的电影
    for (Movie movie : userHistory){
        candidateMap.remove(movie.getMovieId());
    }
    //形成最终的候选集
    return new ArrayList<>(candidateMap.values());
}
```

Embedding召回：一方面，多召回中使用的“兴趣标签”“热门度”“流行趋势”“物品属性”等信息都可以作为 Embedding 方法中的附加信息（Side Information），融合进最终的 Embedding 向量中 。因此，在利用 Embedding 召回的过程中，我们就相当于考虑到了多路召回的多种策略。另一方面，Embedding 召回的评分具有连续性。我们知道，多路召回中不同召回策略产生的相似度、热度等分值不具备可比性，所以我们无法据此来决定每个召回策略放回候选集的大小。但是，Embedding 召回却可以把 Embedding 间的相似度作为唯一的判断标准，因此它可以随意限定召回的候选集大小。

在 SparrowRecsys 中，我们也实现了基于 Embedding 的召回方法。

```java

public static List<Movie> retrievalCandidatesByEmbedding(User user){
    if (null == user){
        return null;
    }
    //获取用户embedding向量
    double[] userEmbedding = DataManager.getInstance().getUserEmbedding(user.getUserId(), "item2vec");
    if (null == userEmbedding){
        return null;
    }
    //获取所有影片候选集(这里取评分排名前10000的影片作为全部候选集)
    List<Movie> allCandidates = DataManager.getInstance().getMovies(10000, "rating");
    HashMap<Movie,Double> movieScoreMap = new HashMap<>();
    //逐一获取电影embedding，并计算与用户embedding的相似度
    for (Movie candidate : allCandidates){
        double[] itemEmbedding = DataManager.getInstance().getItemEmbedding(candidate.getMovieId(), "item2vec");
        double similarity = calculateEmbeddingSimilarity(userEmbedding, itemEmbedding);
        movieScoreMap.put(candidate, similarity);
    }
   
    List<Map.Entry<Movie,Double>> movieScoreList = new ArrayList<>(movieScoreMap.entrySet());
    //按照用户-电影embedding相似度进行候选电影集排序
    movieScoreList.sort(Map.Entry.comparingByValue());


    //生成并返回最终的候选集
    List<Movie> candidates = new ArrayList<>();
    for (Map.Entry<Movie,Double> movieScoreEntry : movieScoreList){
        candidates.add(movieScoreEntry.getKey());
    }
    return candidates.subList(0, Math.min(candidates.size(), size));
}
```


![image.png](:/536da8bf6df44301bdf07109bf597c2c)


“召回层”一般由高效的召回规则、算法或简单的模型组成，这让推荐系统能快速从海量的候选集中召回用户可能感兴趣的物品。

基于tag的显式召回和基于embedding的隐式召回。

## 1. 规则类召回（最新、最热关键词等）

## 2. 协同过滤召回（ICF、UCF、Swing）

* ICF：如果喜欢两个item的受众重叠较大，那么相似度大(集合). $sim(i_1, i_2) = \frac{|U_1 \cap U_2|}{\sqrt {|U_1||U_2|}}$, $U_1, U_2$为喜欢物品$i_1, i_2$的用户集合
* Swing：两个物品的相似度由喜欢物品的用户之间的相似度来衡量

  $$
  sim(i_1, i_2) = \sum_{u_1\in V}\sum_{u_2\in V}\frac{1}{\alpha + overlap(u_1,u_2)}
  $$

  $V$为同时喜欢两个物品的用户集合，$overlap(u_1, u_2)$表示的是两个用户喜欢物品集合的交集
* UCF：思路是找到相似用户对不同物品的喜好，并加权得到物品的分数$\sum_{u_j} sim(u_i, u_j) Like(u_j, item)\\sim(u_i, u_j) = \frac{|I_i \cap I_j|}{\sqrt {|I_i||I_j|}}\\ sim(u_i, u_j) = \frac{\sum_{i\in {I_i \cap I_j}\frac{1}{log{(1 + n_i)}}}}{\sqrt {|I_i||I_j|}}[n_l\text{为物品热度系数， 打压热门物品对相似度贡献]}\\$



## 3. 向量召回：

DSSM: **最大的特点就是「user和item是独立的两个子网络」**，**「User特征」**主要包括和用户相关的特征：用户id、手机系统、地域、年龄、历史行为序列等。**「Item特征」**主要包括和Item相关的特征：ItemId、Item类别、Item来源等

**速度快**：离线构图 + 最近邻检索。可以离线将所有的Item通过Item塔得到其向量，并将Item向量保存在FAISS中。而双塔模型速度快就是因为其能离线将item向量保存在FAISS这样的ANN（Approximate Nearest Neighbor Search）框架中

**余弦相似度：**欧氏距离会随著维度增加而增大。如果使用余弦相似度的话，数值上会保持在-1到1之间，正交时为0，方向相反时候为-1

**最后一层L2 normalization:** cosine相似度（距离）并不保证传递性，加上归一化后可以将结果映射到欧式空间，保证训练检索的一致性（加强了训练目标）[缺点是缩小了梯度，使得收敛几乎不可能]

**和归一化几乎绑定的temperature**：如果一个人做过双塔模型，又使用了归一化操作，他一定知道没有temperature模型几乎收敛不了。对 logits 除上一个 temperature 系数的作用是扩大 logits 中每个元素中的上下限, 拉回 softmax 运算的敏感范围。

**存在的问题**：1. 特征交叉和用户、item交互学习能力有限； 2. 只有最后一层有交互、交叉能力，无法对细粒度特征进行有效的提取

**特征重要性筛选**：把SENet放在Embedding层之上，目的是通过SENet网络，动态地学习这些特征的重要性 ai ：对于每个特征学会一个特征权重，然后再把学习到的权重乘到对应特征的Embedding里，这样就可以动态学习特征权重，通过小权重抑制噪音或者无效低频特征，通过大权重放大重要特征影响的目的。SENet分为两个步骤：Squeeze 阶段和Excitation阶段。在**Squeeze阶段**，我们对每个特征的Embedding向量进行数据压缩与信息汇总，假设某个特征**v_i**是**k**维大小的embedding，那么我们对**k**维数字求均值，得到能够代表这个特征总信息的数值$z_i=F_sq(v_i)=\frac{1}{k}\sum_{t=1}^k v_i^t$，也就是说，把第**i**个特征的embedding里的信息压缩到一个数值。在Exicitation阶段，我们引入中间层比较窄的两层MLP网络，作用输出向量**Z**上$S=F_{ex}(Z,W)=\phi(W_2\phi(W_1Z))$，其中$\phi$是非线性函数，一般取Relu，这层主要做特征的交叉。

**训练数据选择问题**：一般会用“用户点击”实例做为正例，“曝光未点击”实例做为负例，来训练模型。也都是用“用户点击”实例做为正例，但是怎么选择负例，这里面有不少学问
**Sample selection bias问题**：我们先来看下不同阶段模型面对的输入数据情况，对于召回模型来说，它面临的输入数据，是所有物料库里的物品；对于粗排模型来说，它面对的输入数据，是各路召回的结果；对于精排模型来说，它面临的输入是粗排模型的输出结果。如果我们仍然用“曝光未点击”实例做为召回和粗排的负例训练数据，你会发现这个训练集合，只是全局物料库的一小部分，它的分布和全局物料库以及各路召回结果数据，这两个召回和粗排模型面临的实际输入数据，分布差异比较大，所以根据这种负例训练召回和粗排模型，效果如何就带有疑问，我们一般把这个现象称为“Sample Selection Bias”问题。可选的负例选择方法

* **曝光未点击数据：这个数据还是需要的，只是要和其它类型的负例选择方法，按照一定比例进行混合，来缓解Sample Selection Bias问题**
* **全局随机选择负例：在原始的全局物料库里，随机抽取做为召回或者粗排的负例。从道理上讲，这个肯定是完全符合输入数据的分布一致性的，但是，一般这么选择的负例，因为和正例差异太大，导致模型太好区分正例和负例，所以模型能学到多少知识是成问题的。**
* **Batch内随机选择负例：就是说只包含正例，训练的时候，在Batch内，选择除了正例之外的其它Item，做为负例。这个本质上是：给定用户，在所有其它用户的正例里进行随机选择，构造负例。**
* **曝光数据随机选择负例：在给所有用户曝光的数据里，随机选择做为负例。这个我们测试过，在某些场景下是有效的。**
* **基于Popularity随机选择负样例：全局随机选择，但是越是流行的Item，越大概率会被选择作为负例。目前不少研究证明了，负例采取Popularity-based方法，对于效果有明显的正面影响。它隐含的假设是：如果一个例子越流行，那么它没有被用户点过看过，说明更大概率，对当前的用户来说，它是一个真实的负例。同时，这种方法还会打压流行Item，增加模型个性化程度。**
* **基于Hard选择负样例：它是选择那些比较难的例子，做为负例。因为难区分的例子，很明显给模型带来的loss和信息含量比价多，所以从道理上讲是很合理的。但是怎样算是难的例子，可能有不同的做法，有些还跟应用有关。**
* **论文Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations  **[iwtbs：借Youtube论文，谈谈双塔模型的八大精髓问题](https://zhuanlan.zhihu.com/p/369152684)

**Wide & Deep**

**Product-based Neural Networks for User Response Prediction：**

**DeepFM：A Factorization-Machine based Neural Network for CTR Prediction**

[推荐中的召回算法总结串讲](https://zhuanlan.zhihu.com/p/364053939)

[iwtbs：《Embedding-based Retrieval in Facebook Search》论文精读](https://zhuanlan.zhihu.com/p/395200364)


双塔教程：https://bbs.huaweicloud.com/blogs/360668


id: df2c13dae92f4126859cfc5de1543c98
parent_id: 8af0105890f3497ab59d5e8eddee68d0
created_time: 2023-03-25T10:09:45.191Z
updated_time: 2023-03-31T12:47:38.945Z
is_conflict: 0
latitude: 0.00000000
longitude: 0.00000000
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 1680266858826
user_created_time: 2023-03-25T10:09:45.191Z
user_updated_time: 2023-03-31T12:47:38.945Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
type_: 1