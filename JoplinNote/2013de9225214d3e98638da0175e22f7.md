id: 2013de9225214d3e98638da0175e22f7
parent_id: 
item_type: 1
item_id: 60439635ffb74a189448bd6dfb12ecd9
item_updated_time: 1686823201979
title_diff: "[{\"diffs\":[[1,\"Notes - deep learning - a bayesian perspective\"]],\"start1\":0,\"start2\":0,\"length1\":0,\"length2\":46}]"
body_diff: "[{\"diffs\":[[1,\"Bayesian probabilistic perspective provides a number insights into more efficient algorithms for optimization and hyper-parameter tuning.\\\n\\\nIn comparison to traditional high-dimensional data reduction techniques, such as principal component analysis(PCA), partial least squares (PLS), reduced rank regression (RRR), projection pursuit regres-\\\nsion (PPR) are all shown to be shallow learners. Their deep learning counterparts exploit\\\nmultiple deep layers of data reduction which provide predictive performance gains\\\n\\\nStochastic gradient descent (SGD) training optimisation and Dropout (DO) regularization provide\\\n**estimation and variable selection**. Bayesian regularization is central to finding weights and\\\nconnections in networks to optimize the predictive bias-variance trade-off\"]],\"start1\":0,\"start2\":0,\"length1\":0,\"length2\":782}]"
metadata_diff: {"new":{"id":"60439635ffb74a189448bd6dfb12ecd9","parent_id":"092da0c34f3d46b58883166b6be22040","latitude":"31.23041600","longitude":"121.47370100","altitude":"0.0000","author":"","source_url":"","is_todo":0,"todo_due":0,"todo_completed":0,"source":"joplin-desktop","source_application":"net.cozic.joplin-desktop","application_data":"","order":0,"markup_language":1,"is_shared":0,"share_id":"","conflict_original_id":"","master_key_id":""},"deleted":[]}
encryption_cipher_text: 
encryption_applied: 0
updated_time: 2023-06-15T10:03:53.138Z
created_time: 2023-06-15T10:03:53.138Z
type_: 13