2.7 多任务学习

1. 最近接触到的几个大厂推荐系统排序模型都无一例外的在使用多任务学习，比如腾讯PCG在推荐系统顶会RecSys 2020的最佳长文：  
    Progressive Layered Extraction (PLE): A Novel Multi-Task Learning (MTL) Model for Personalized Recommendations；  
    2019年RecSys中Youtube排序模块论文：  
    Recommending what video to watch next: a multitask ranking system；  
    以及广告推荐、新闻推荐、短视频推荐、问答推荐算法工程师们都经常使用/尝试过的MMOE模型Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts。  
    当然还有诸多优秀的多任务学习就不在此一一列举啦。
2. NLP中著名的多跳（multi-hop）问答数据集榜单HotpotQA上出现了一个多任务问答框架（2020年11月是榜1模型，名字叫IRRR），把open domain question answering中的信息抽取，排序，问答统一用一个模型来解决，既简洁又拿了高分！  
    引用斯坦福nlp组里这篇论文的原话：  
    We employ a single multi-task model to perform all the necessary subtasks---retrieving supporting facts, reranking them, and predicting the answer from all retrieved documents---in an iterative fashion。

![image.png](:/95e78b4413604a888db1308fc0b58dd4)

上图左侧为单任务学习，右侧为多任务学习。单任务学习vs多任务学习直白解释：

单任务学习（single task learning）： **一个loss，一个任务，例如NLP里的情感分类、NER任务一般都是可以叫单任务学习** 。

多任务学习（multi task learning）： **简单来说有多个目标函数loss同时学习的就算多任务学习。** 例如现在大火的短视频，短视频APP在向你展示一个大长腿/帅哥视频之前，通常既要预测你对这个视频**感兴趣/不感兴趣，看多久，点赞/不点赞，转发/不转发**等多个维度的信息。这么多任务既可以每个任务都搞一个模型来学，也可以一个模型多任务学习来一次全搞定的。


### 多任务提效原因

对于有监督深度学习/机器学习而言，基本流程都是通过输入数据，模型根据输入数据来预测结果，训练阶段根据预测和监督信号之间的差异（loss）来修正模型的参数，让模型参数尽可能可能符合数据的分布。

模型统一，方便、高效、效果好，

1. **成本更加低廉**：一次搞定多个任务，这点对工业界友好。假设要用k个模型预测k个任务，那么k个模型预测的时间成本、计算成本、存储成本、甚至还有模型的维护成本都是大于一个模型的。
2. **隐式数据增强，缓解数据稀疏问题**: 每个任务都有自己的样本，使用多任务学习的话，模型的样本量会提升很多。而且数据都会有噪声，如果单学A任务，模型会把A数据的噪声也学进去，如果是多任务学习，模型因为要求B任务也要学习好，就会忽视掉A任务的噪声，同理，模型学A的时候也会忽视掉B任务的噪声，因此多任务学习可以学到一个更精确的嵌入表达。
3. **提高模型泛化能力**：多任务学习能提高泛化能力，从另一个角度来看，对于数据很少的新任务，也解决了所谓的“冷启动问题”。
4. **任务互助**：某些任务所需的参数可以被其他任务辅助训练的更好，比如任务A由于各种限制始终学不好W1，但是任务B却可以轻松将W1拟合到适合任务A所需的状态

**hard parameter sharing**和 **soft parameter sharing** 。区别在于对图1右边MTL那一个方块。

![image.png](:/1129c8ded4cd4cbf8a10407d106ebae2)

hard parameter sharing依旧是很好用的baseline系统，无论最后有多少个任务，底层参数统一共享，顶层参数各个模型各自独立。soft parameter sharing是现代研究的重点方向。底层共享一部分参数，自己还有独特的一部分参数不共享；

结构设计：

* **竖着切了吃：** 对共享层进行区分，也就是想办法给每个任务一个独特的共享层融合方式。图3的MOE和MMOE模型就是竖着切了吃的例子。另外MMOE在MOE的基础上，多了一个GATE，意味着：多个任务既有共性（关联），也必须有自己的独特性（Task specific）。共性和独特性如何权衡：每个任务搞一个专门的权重学习网络（GATE），让模型自己去学，学好了之后对expert进行融合送给各自任务的tower，最后给到输出，2019年的SNR模型依旧是竖着切开了吃，只不过竖着切开了之后还是要每一小块都分一点放一起送给不同的流口水的人。![image.png](:/9c1f93f086db4e6aacf3f8a54af3191c)
* **一层层拿来吃** ：对不同任务，不同共享层级的融合方式进行设计。如果共享网络有多层，那么通常我们说的高层神经网络更具备语义信息，那我们是一开始就把所有共享网络考虑进来，还是从更高层再开始融合呢？如图6最右边的PLE所示，Input上的第1层左边2个给了粉色G，右边2个给了绿色G，3个都给了蓝色G，然后第2层左边2块给左边的粉色G和Tower，右边两块输出到绿色G和Tower。![image.png](:/468d7d7857994542899a74ad015b88f9)

**多目标loss设计和优化**

1. 根据任务的Uncertainty对权重进行计算，读者可参考经典的： Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics。
2. 由于不同loss取值范围不一致，那么是否可以尝试通过调整loss的权重w让每个loss对共享Wsh 参数贡献平等呢？GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks，另外一篇相似思路的文章End-to-end multi-task
3. learning with attention 提出一种Dynamic Weight Averaging的方法来平衡不同的学习任务。
4. Multi-Task Learning as Multi-Objective Optimization对于MTL的多目标优化理论分析十分有趣，对于MTL优化理论推导感兴趣的同学值得一看。

利用Pareto optimization，求解多目标梯度优化(这个是未来主流的方向):

* Multi-Task Learning as Multi-Objective Optimization
* Multi-Gradient Descent for Multi-Objective Recommender Systems

优化算法概略：https://mp.weixin.qq.com/s/eIzWfkI3D1ihAeq2SFd8YQ

**设计更合理的辅助任务**：

辅助任务设计的常规思路：

1. 找相关的辅助任务！
2. 对于相关任务不太好找的场景可以尝试一下对抗任务，比如学习下如何区分不同的domain的内容。

阿里的DIN：Deep Interest Evolution Network for Click-Through Rate Prediction，看看阿里爸爸如何科学的加入辅助loss。另一篇ESSM也可以从辅助任务设计这个角度学习学习：Entire Space Multi-Task Model: An Effective Approach for Estimating Post-Click Conversion Rate。

个人实践中， **先过滤掉一些噪声段落，再进行QA大概率都是会提升QA效果的** ～～特别是有了预训练BERT、Roberta、XLNET这些大规模语言模型之后。对于multilingual task和MT（机器翻译），其实有个比较简单的思路就是多个语言、多模态一起学，天然的辅助任务/多任务。另外在以前的机器翻译任务里）大家还喜欢加上POS/NER这种任务来辅助翻译。比如微软，Multi-Task Deep Neural Networks for Natural Language Understanding，百度的ERNIE 2.0: A Continual Pre-Training Framework for Language Understanding



放上几个经典的代码库，方便大家操作和学习：

1. multi task example：https://github.com/yaringal/multi-task-learning-example.git
2. MMOE https://github.com/drawbridge/keras-mmoe.git
3. NLP福利库包含各大SOTA的BERT类模型：

https://github.com/huggingface/transformers.git

1. 百度ERNIE https://github.com/PaddlePaddle/ERNIE.git
2. 微软MT-DNN https://github.com/namisan/mt-dnn.git



## * 参考内容

1. Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics。
2. ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation
3. ERNIE 2.0: A Continual Pre-Training Framework for Language Understanding
4. Multi-Task Deep Neural Networks for Natural Language Understanding
5. A Frustratingly Easy Approach for Joint Entity and Relation Extraction
6. https://ruder.io/multi-task-learning-nlp/
7. Entire Space Multi-Task Model: An Effective Approach for Estimating Post-Click Conversion Rate
8. Deep Interest Evolution Network for Click-Through Rate Prediction
9. Progressive Layered Extraction (PLE): A Novel Multi-Task Learning (MTL) Model for Personalized Recommendations
10. https://zhuanlan.zhihu.com/p/32423092
11. Multi-Task Learning as Multi-Objective Optimization
12. https://zhuanlan.zhihu.com/p/68846373
13. GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks
14. Multi-Task Learning for Dense Prediction Tasks:A Survey
15. Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts
16. https://zhuanlan.zhihu.com/p/27421983
17. https://zhuanlan.zhihu.com/p/59413549
18. https://ruder.io/multi-task/
19. https://cs330.stanford.edu/


id: 7e2433cd8b184cfabb12a175445cc2b8
parent_id: 8af0105890f3497ab59d5e8eddee68d0
created_time: 2023-03-25T10:09:45.235Z
updated_time: 2023-03-31T12:47:40.945Z
is_conflict: 0
latitude: 0.00000000
longitude: 0.00000000
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 1680266860896
user_created_time: 2023-03-25T10:09:45.235Z
user_updated_time: 2023-03-31T12:47:40.945Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
type_: 1